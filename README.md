# ğŸ“˜ Snowflake Data Blueprint

Designed to teach Snowflake ingestion using modern tools, scalable workflows, and real-world datasets.

---

## ğŸ“¦ Featured Datasets

| Dataset                  | Format       | Workflow Overview                                       |
|--------------------------|--------------|----------------------------------------------------------|
| Retail Product Sales     | CSV          | `COPY INTO` â†’ `Stream + Task` â†’ Revenue dashboard       |
| Global Power Plants      | JSON & CSV   | Snowpipe â†’ Error validation â†’ Metadata enrichment       |
| COVID-19 Daily Reports   | CSV          | Real-time ingestion â†’ Rolling averages pipeline         |

---

## ğŸ¯ Learning Objectives

- Learn how to use **Stages**, **File Formats**, and `COPY INTO` for structured ingestion.
- Automate ingestion pipelines with **Snowpipe**, **Streams**, and **Tasks**.
- Trigger ingestion with **Python REST API**.
- Monitor ingestion using `COPY_HISTORY` and `SNOWPIPE_USAGE_HISTORY`.
- Practice **error handling**, **validation**, and **data quality control**.
- Explore forward-looking features like **Snowflake Native Apps**, **Cortex AI**, and **Unistore**.

---

## ğŸ—‚ï¸ Project Structure

```bash
snowflake-data-blueprint/
â”œâ”€â”€ data/          # Raw datasets from data.world
â”œâ”€â”€ sql/           # SQL scripts: COPY INTO, pipes, streams, tasks
â”œâ”€â”€ python/        # Python scripts to trigger Snowpipe via REST API
â”œâ”€â”€ diagrams/      # Visual architecture and pipeline flows
â”œâ”€â”€ exercises/     # Chapter-wise challenges and quizzes
â””â”€â”€ README.md      # Youâ€™re here!
```

---

## ğŸš€ Getting Started

### 1. Clone the Repo

```bash
git clone https://github.com/mohammedali899/snowflake-data-blueprint.git
cd snowflake-data-blueprint
```

### 2. Create a Target Table

```sql
CREATE TABLE retail_orders (
  product_id INT,
  category STRING,
  price FLOAT,
  units_sold INT,
  order_date DATE
);
```

### 3. Load Data using COPY INTO

```sql
COPY INTO retail_orders
FROM @retail_stage
FILE_FORMAT = (TYPE = 'CSV' SKIP_HEADER = 1)
ON_ERROR = 'CONTINUE';
```

---

## ğŸ§ª Challenge Yourself

Try these bonus tasks:

- âœ… Use `VALIDATION_MODE = 'RETURN_ERRORS'` before loading.
- âœ… Create a **stream** on the raw table and a **task** to populate a clean table.
- âœ… Set up a **pipe** and trigger ingestion using a Python script from `python/`.

---

## ğŸ“Š Monitoring Tips

Use these queries to track ingestion performance:

```sql
-- Snowpipe Monitoring
SELECT * FROM SNOWPIPE_USAGE_HISTORY WHERE PIPE_NAME = 'PIPE_ORDERS';

-- COPY INTO Monitoring
SELECT * FROM COPY_HISTORY WHERE TABLE_NAME = 'RETAIL_ORDERS';
```

---

## ğŸ§  Interview Readiness

ğŸ’¡ Be prepared to explain:

- How `COPY INTO` differs from `Snowpipe`
- Why `STORAGE_INTEGRATION` is important for secure ingestion
- How `Streams` and `Tasks` automate transformation workflows

---

## ğŸ§  About the Author

Built by **Mohammed Ali**, data engineer and educator.  
ğŸ“˜ Part of the [Snowflake Data Engineering Blueprint](https://yourcoursepage.com) learning series.

---

## ğŸ“œ License

This project is open-source and free for learning use.  
You may **fork**, **clone**, and **contribute**.

---

## ğŸ¤ Contributions

Pull requests welcome. Feel free to open issues for suggestions or bugs.
